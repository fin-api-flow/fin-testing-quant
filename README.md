# fin-testing-quant
Some financial testing apps leveraging LLM's. 


# fin-testing-quant

> **Financial testing apps, powered by Large Language Models (LLMs)**

![License](https://img.shields.io/badge/License-MIT-blue.svg) ![Python](https://img.shields.io/badge/Python-3.10%2B-blue)

---

## ğŸ“– Overview

`fin-testing-quant` is a collection of experimental tools and miniâ€‘apps that explore how modern LLMs can accelerate quantitative research and portfolio testing workflows. The repo bundles data connectors, promptâ€‘driven analysis helpers, and reproducible notebooks that show how to:

* Generate hypothesisâ€‘driven trading strategies in plain English and translate them into executable Python backâ€‘tests.
* Stressâ€‘test models with synthetic market regimes produced by LLMâ€guided scenario generation.
* Explain trade performance in natural language for automated report writing.

> **Disclaimer**
> This code is provided **for research and educational purposes only** and should **not** be considered investment advice in any form.

---

## âš¡ï¸ Key Features

| Area                   | Highlights                                                                                       |
| ---------------------- | ------------------------------------------------------------------------------------------------ |
| **Promptâ€‘toâ€‘Backtest** | Convert prose strategy specs into vectorized Pandas backâ€‘tests via the `llm_backtester` package. |
| **Scenario Generator** | Leverage GPTâ€‘4o to fabricate tailâ€‘risk market paths for stress analysis.                         |
| **Explainability**     | Summarise P\&L drivers, drawdowns, and factor exposures in readable paragraphs.                  |
| **Plugâ€‘andâ€‘Play Data** | Builtâ€‘in loaders for Yahoo Finance, FRED, and Polygon.io (optional).                             |
| **Modular Design**     | Each component can be used standalone or orchestrated via a CLI.                                 |

---

## ğŸ—ï¸ Repository Structure

```
fin-testing-quant/
â”œâ”€â”€ apps/                # Streamlit & FastAPI frontâ€‘ends
â”œâ”€â”€ data/                # Lightweight dataset samples (<1â€¯MB)
â”œâ”€â”€ llm_backtester/      # Core library â€“ prompt parser â†’ vectorized engine
â”œâ”€â”€ notebooks/           # Jupyter demos & case studies
â”œâ”€â”€ tests/               # Pytest suites & fixtures
â”œâ”€â”€ .env.example         # Environment variable template
â””â”€â”€ pyproject.toml       # Poetry build config
```

---

## ğŸš€ Quickstart

```bash
# 1. Clone the repo
$ git clone https://github.com/yourâ€‘org/fin-testing-quant.git && cd fin-testing-quant

# 2. Install dependencies (Poetry recommended)
$ poetry install --with dev

# 3. Set your OpenAI (or Azure OpenAI) key
$ cp .env.example .env  # then edit

# 4. Run a sample notebook
$ poetry run jupyter lab notebooks/01_basic_prompt_backtest.ipynb
```

> **Note:** GPU is **not** required; CPU works fine for the examples.

---

## ğŸ› ï¸ Configuration

Environment variables (see `.env.example`):

| Variable         | Purpose                           |
| ---------------- | --------------------------------- |
| `OPENAI_API_KEY` | API key for OpenAI models         |
| `DATA_PROVIDER`  | `yfinance`, `polygon`, or `local` |
| `MAX_TOKENS`     | Token budget for LLM calls        |

---

## ğŸ’» Usage Examples

### 1. English â†’ Backâ€‘Test

```python
from llm_backtester import StrategyLLM

spec = "Long the S&PÂ 500 when the 50â€‘day SMA crosses above the 200â€‘day SMA; exit when it crosses below."
results = StrategyLLM().backtest(spec, ticker="SPY", start="2010-01-01")
results.plot_equity_curve()
```

### 2. Generate Stress Scenarios

```python
from llm_backtester import ScenarioFactory
scenarios = ScenarioFactory().generate("COVIDâ€‘style liquidity crunch lasting 3 months")
```

### 3. CLI Workflow

```bash
$ poetry run finâ€‘quant genâ€‘strategy --prompt "Pairs trade EURUSD vs GBPUSD based on PPP divergence"
```

---

## âœ”ï¸ Testing & Linting

```bash
$ poetry run pytest          # Run unit tests
$ poetry run coverage html   # Generate coverage report
$ poetry run ruff check .    # Static analysis
```

---

## ğŸ—ºï¸ Roadmap

* [ ] LangChain agent support for multiâ€‘step research chains
* [ ] Vectorâ€‘store caching for prompt results
* [ ] Reinforcement learning loop to autoâ€‘tune strategy parameters

Feel free to open issues or vote on features!

---

## ğŸ¤ Contributing

1. Fork the project and create your branch: `git checkout -b feature/AmazingFeature`
2. Commit your changes: `git commit -m 'Add some AmazingFeature'`
3. Push to the branch: `git push origin feature/AmazingFeature`
4. Open a pull request

All contributions must pass CI (tests, lint, formatting) before review.

---

## ğŸ“„ License

Distributed under the **MIT License**. See `LICENSE` for more information.

---

## ğŸ“¬ Contact & Credits

* **Maintainer:** [YourÂ Name](mailto:you@example.com)
* Powered by [OpenAI](https://openai.com) and the amazing openâ€‘source quant community.

---

*Happy backâ€‘testing! ğŸš€*
